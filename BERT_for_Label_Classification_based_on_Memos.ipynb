{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Hack Foundation Problem:\n",
        "\n",
        "ML model for tagging transactions.\n"
      ],
      "metadata": {
        "id": "zs9BcDDUirH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "Ei2tBCl7Ydas"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "AM0Tz0-RhEvC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "#!pip install torch.     # commented because it is pre-installed in Colab\n",
        "!pip install torchtext\n",
        "!pip install transformers\n",
        "#!pip install numpy      # commented because it is pre-installed in Colab\n",
        "!pip install portalocker\n",
        "!pip install pandas\n",
        "!pip install numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torchtext import data as torchtext_data\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, BertConfig, BertModel, BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "GhoH5AXPnL_H"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = torch.device(\"mps\")               # in case you run on a local Mac with metal performance shaders (setup/support is up to you)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtkwLcrfn1PL",
        "outputId": "be407bed-56b7-4ee9-a369-21f1567378f5"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(10)\n",
        "np.random.seed(10)"
      ],
      "metadata": {
        "id": "I8fj14tzqlQz"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mount Google Drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define your directory\n",
        "output_folder = \"/content/drive/MyDrive/Hack for Impact 2024/\"\n",
        "\n",
        "# Ensure the output directory exists\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2UYAKz6n2Br",
        "outputId": "f7790654-4e62-470c-ffd7-407cb28d16bd"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "w3boNyYgEfNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "def get_additional_memo(csv_line: list[str]) -> str:\n",
        "  \"\"\"\n",
        "  Checks the check, donation, invoice, and transfer memo for any additional memo\n",
        "\n",
        "  Returns an empty string if all of those are also empty\n",
        "  \"\"\"\n",
        "  if csv_line[6] != '':\n",
        "    return csv_line[6]\n",
        "\n",
        "  if csv_line[7] != '':\n",
        "    return csv_line[7]\n",
        "\n",
        "  if csv_line[8] != '':\n",
        "    return csv_line[8]\n",
        "\n",
        "  if csv_line[9] != '':\n",
        "    return csv_line[9]\n",
        "\n",
        "def get_dataset():\n",
        "  \"\"\"\n",
        "  Reads the CSV file and parses all of them into an array of dictionaries\n",
        "  \"\"\"\n",
        "\n",
        "  data = []\n",
        "  with open('/content/drive/MyDrive/Hack for Impact 2024/transactions3.csv', mode ='r')as file:\n",
        "    csvFile = csv.reader(file)\n",
        "    first = True\n",
        "    for line in csvFile:\n",
        "      if first:\n",
        "        first = False\n",
        "        continue\n",
        "      try:\n",
        "        data.append({\n",
        "          \"amount_cents\": line[0],\n",
        "          \"memo\": line[1],\n",
        "          \"date\": line[2],\n",
        "          \"type\": line[3],\n",
        "          \"tags\": json.loads(line[4].replace(\"'\", '\"').replace('✈️\\\\xa0', '🛫')),\n",
        "          \"org_category\": line[4],\n",
        "          \"org_id\": line[5],\n",
        "          \"additional_memo\": get_additional_memo(line)\n",
        "        })\n",
        "      except:\n",
        "        print(line)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "eU02lEERTdCJ"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = get_dataset()"
      ],
      "metadata": {
        "id": "uib_9HINTrNh"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_data = [obs for obs in data if obs['tags'] != []]"
      ],
      "metadata": {
        "id": "sO6-vmu8UOE4"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optional label map, unused for now.\n",
        "label_map = {\n",
        "    \"💰 Funding\": \"Funding\",\n",
        "    \"2024BakeSale\": \"Events\",\n",
        "    \"🎁 Travel Stipends\": \"Travel\",\n",
        "    \"🍕 Food\": \"Food\",\n",
        "    \"🎾Outernet Guilds\": \"Teambuilding\",\n",
        "    \"Prizes\": \"Events\",\n",
        "    \"💻 Network Equipment Purchase\": \"IT\",\n",
        "    \"♾️ Subscription/bill\": \"Subscription\",\n",
        "    \"Marketing mail campaign\": \"Marketing\",\n",
        "    \"✈️ Team Travel\": \"Travel\",\n",
        "    \"🥗 Team Food\": \"Food\",\n",
        "    \"Sponsorships\": \"Funding\",\n",
        "    \"ComicConBakeMay2023\": \"Events\",\n",
        "    \"💸 Donations\": \"Funding\",\n",
        "    \"Business\": \"Misc\",\n",
        "    \"↪️ Reimbursement\": \"Reimbursement\",\n",
        "    \"💳 Misc. Expenses\": \"Misc\",\n",
        "    \"sponsorship\": \"Funding\",\n",
        "    \"🌯 Team Food\": \"Food\",\n",
        "    \"👕 Swag\": \"Marketing\",\n",
        "    \"🧩 development of things doing stuff\": \"Operations\",\n",
        "    \"2SM 2023\": \"Events\",\n",
        "    \"Tax\": \"Taxes\",\n",
        "    \"2SM2023\": \"Misc\",\n",
        "    \"🔌 Supplies\": \"IT\",\n",
        "    \"Mechanical\": \"IT\",\n",
        "    \"💸 Sponsor\": \"Funding\",\n",
        "    \"Funding\": \"Funding\",\n",
        "    \"🌱 Sprig\": \"Misc\",\n",
        "    \"🧘 Healthcare\": \"Labor\",\n",
        "    \"Programing\": \"Labor\",\n",
        "    \"⚙️ Supplies\": \"IT\",\n",
        "    \"🎁 Travel Stipend\": \"Travel\",\n",
        "    \"Marketing/Logo\": \"Marketing\",\n",
        "    \"HCBfees\": \"Subscription\",\n",
        "    \"Oxfam\": \"Misc\",\n",
        "    \"📣 Marketing\": \"Marketing\",\n",
        "    \"Corporate Rental Fee Income\": \"Operations\",\n",
        "    \"Test Wiz\": \"Misc\",\n",
        "    \"🛫Travel Stipend\": \"Travel\",\n",
        "    \"🛫 Flights\": \"Travel\",\n",
        "    \"🔌 Logistics Supplies\": \"IT\",\n",
        "    \"🎨Blot\": \"Operations\",\n",
        "    \"Reimbursement\": \"Reimbursement\",\n",
        "    \"📝 Supplies\": \"Operations\",\n",
        "    \"Travel/Meals\": \"Travel\",\n",
        "    \"Sponsor\": \"Funding\",\n",
        "    \"🌉 Assemble\": \"Misc\",\n",
        "    \"Marketing 📈\": \"Marketing\",\n",
        "    \"Hack Club/HCB HQ\": \"Subscription\",\n",
        "    \"🧰 Supplies\": \"Operations\",\n",
        "    \"🏠 Office\": \"IT\",\n",
        "    \"Equipment\": \"IT\",\n",
        "    \"✨ Workshops & Activities Supplies\": \"Operations\",\n",
        "    \"Supplies\": \"Operations\",\n",
        "    \"💰 Team Expenses Repaid\": \"Reimbursement\",\n",
        "    \"🤡 Disputed\": \"Refund\",\n",
        "    \"📋 Advertisement\": \"Marketing\",\n",
        "    \"⏪ Refunded Charge\": \"Refund\",\n",
        "    \"🍱 Food\": \"Food\",\n",
        "    \"✈️ Travel\": \"Travel\",\n",
        "    \"💸 Payroll\": \"Labor\",\n",
        "    \"🏆Prizes\": \"Events\",\n",
        "    \"HCB Fee\": 'Subscription',\n",
        "    'event meal': 'Food',\n",
        "    '🧃 Drinks': 'Food',\n",
        "    '💰Contractor Payments': 'Labor',\n",
        "    'HQ': 'Subscription',\n",
        "    '💻 Employee hardware':'IT',\n",
        "    '💸 De-funding':'Funding',\n",
        "    'grants': 'Funding',\n",
        "    'Vendor Payment': 'Labor',\n",
        "    '2SM2024': 'Misc',\n",
        "    'Feb2023Bake': 'Sales',\n",
        "    'Email': 'IT',\n",
        "    '💰 Grants': 'Funding',\n",
        "    '🥤Snacks & Drinks': 'Food',\n",
        "    'Merch': 'Marketing',\n",
        "    'Fundraising': 'Funding',\n",
        "    '🏺 Decorations': 'Marketing',\n",
        "    'Event': 'Events',\n",
        "    'Grant': 'Funding',\n",
        "    'Focus Facilitator': 'Misc',\n",
        "    '📈Marketing': 'Marketing',\n",
        "    'Promo': 'Marekting',\n",
        "    'Toy Drive': 'Events',\n",
        "    'Prize money':'Events',\n",
        "    '🍝Cookhouse': 'Food',\n",
        "    'Burning Man Participant':'Events',\n",
        "    '4 Hour Round Trip UC Davis Veterinary Clinic Road Trip Volunteer Meal':'Food',\n",
        "    '🎊 Prizes':'Events',\n",
        "    '🏆 Prizes':'Events',\n",
        "    '❤️ Team Mementos':'Marketing',\n",
        "    'Food':'Food',\n",
        "    '💝 Donations':'Funding',\n",
        "    'Test':'Misc',\n",
        "    'Donation':'Funding',\n",
        "    '💸 Sponsorship':\"Funding\",\n",
        "    'Hack Clubber donations': 'Funding',\n",
        "    '💻 Infra':'IT',\n",
        "    'WDN': 'Misc',\n",
        "    '🌈 Fun Supplies': 'Teambuilding',\n",
        "    '🚀 Meeting Power-Ups': 'Teambuilding',\n",
        "    '💼 Contractors': 'Labor',\n",
        "    'Homepod':'IT',\n",
        "    '💳 Reimbursement':'Reimbursement',\n",
        "    '📦 Shipping': 'Operations',\n",
        "    '🏦 HQ': 'Subscription',\n",
        "    'Indigenous Food Lab': 'Food',\n",
        "    'Marketing': 'Marketing',\n",
        "    'test':'Misc',\n",
        "    '🧪 COVID-19 Supplies': 'Operations',\n",
        "    'Hardware': 'Operations',\n",
        "    'Hardware, misc 🔩': 'Operations',\n",
        "    '💰 Donations': 'Funding',\n",
        "    'Venue': 'Events',\n",
        "    'Prize':'Events',\n",
        "    'Prizes 🏆':'Events',\n",
        "    'Insurance':'Operations',\n",
        "    '💰 Sponsorship / Grant':'Funding',\n",
        "    '🌟Swag':'Marketing',\n",
        "    'TRANSFER':'Operations',\n",
        "    '📜 Scrolls':'Misc',\n",
        "    '🏢 Employee Perks':'Labor',\n",
        "    '🌤️ Insurance':'Operartions',\n",
        "    '🚀 W':'Misc',\n",
        "    '🍇 Catering':'Food',\n",
        "    'Sponsors':'Funding',\n",
        "    'Servers':'Events',\n",
        "    'Printing':'Marketing',\n",
        "    '👕Swag':'Marketing',\n",
        "    '🏗️ Infrastructure':'Operations',\n",
        "    '🎈 Merch':'Marketing',\n",
        "    'Funds':'Funding',\n",
        "    '💰 Sponsorship':'Funding',\n",
        "    '✨ Swag':'Marketing',\n",
        "    'Volunteer Food':'Food',\n",
        "    'Books':'Misc',\n",
        "    'Dog Food':'Food',\n",
        "    'should be reimbursed by Iberia because flight was cancelled':'Travel',\n",
        "    'NSP Volunteer':'Labor',\n",
        "    'Networking Donor Outreach Event':'Events',\n",
        "    'Individual donation':'Funding',\n",
        "    '🎤 Episodes':'Marketing',\n",
        "    'shirts/ swag':'Marketing',\n",
        "    '💂 Security':'Operations',\n",
        "    'Maps':'Misc',\n",
        "    'Merchandise/Spirit Wear':'Marketing',\n",
        "    'Fee':'Misc',\n",
        "    '📦 Supplies':'Operations',\n",
        "    'Donations 💵💵':'Funding',\n",
        "    'haunted house':'Events',\n",
        "    '🍕Food':'Food',\n",
        "    'eBay':'Operations',\n",
        "    '🌲 Social Media & Advertising':'Marketing',\n",
        "    'End of WHW :(':'Misc',\n",
        "    'Two Spirit Wellness Week':'Events',\n",
        "    '🔧 Equipment':'Operations',\n",
        "    '🌐 Domains':'IT',\n",
        "    '✈️Travel Expense':'Travel',\n",
        "    '🌐Website':'IT',\n",
        "    '🍜 Catering':'Food',\n",
        "    '👥 Team Expenses':'Reimbursement',\n",
        "    'Book Repair Supplies':'Misc',\n",
        "    'YCJF':'Misc',\n",
        "    'Zen Master':'Misc',\n",
        "    '🎮Games':'Teambuilding',\n",
        "    'Kit and Kickoff/Registration':'Events',\n",
        "    'Event Costs':'Events',\n",
        "    '🍉Food & Snacks':'Food',\n",
        "    '🎉 Fun':'Teambuilding',\n",
        "    'Orange Pi':'Food',\n",
        "    '🥪 Food':'Food',\n",
        "    'Essentials':'Operations',\n",
        "    '🛠️ Tools for Team':'IT',\n",
        "    'Viasat':'Misc',\n",
        "    'Postage':'Operations',\n",
        "    '🏛️ Staff Resources':'Operations',\n",
        "    'CliDef':'Misc',\n",
        "    '🎁 Prizes':'Events',\n",
        "    '🏆Prize':'Events',\n",
        "    'team snacks':'Food',\n",
        "    'Flat USB':'IT',\n",
        "    'Challenge Coin':'Misc',\n",
        "    'Individual Donation':'Funding',\n",
        "    'Personnel Expense':'Labor',\n",
        "    'Fundraiser Revenue':'Funding',\n",
        "    'community calls':'Marketing',\n",
        "    '😄 Fun!':'Teaambuilding',\n",
        "    '🏆 Prize':'Events',\n",
        "    'Maria flight Kenya - to be reimbursed by FFNPT':'Travel',\n",
        "    '🎉 Prizes':'Events',\n",
        "    'Domain':'IT',\n",
        "    '🎈 Decor':'Events',\n",
        "    'TharpHoodies':'Marketing',\n",
        "    '💻 Maintenance':'IT',\n",
        "    'Refunded':'Reimbursement',\n",
        "    'registration':'Events',\n",
        "    'FTeetersHoodie':'Marketing',\n",
        "    '🚕 Transport':'Travel',\n",
        "    'remimbursement':'Reimbursement',\n",
        "    '💻Laptop':'IT',\n",
        "    'Electric Feather':'Misc',\n",
        "    'Sponsorship 💰💰': 'Funding',\n",
        "    '🙏 Donation':'Funding',\n",
        "    '💝 Venue Gifts':'Events',\n",
        "    'Food / Nutrition Books': 'Misc',\n",
        "    'UMIF':'Misc',\n",
        "    '😭 Lost & Found':'Misc',\n",
        "    '⛺ Outernet':'Teambuilding',\n",
        "    '😋Snacks':'Food',\n",
        "    'Registration':'Events',\n",
        "    'yay':'Misc',\n",
        "    'Website':'IT',\n",
        "    'Inner Peace':'Labor',\n",
        "    'Travel':'Travel',\n",
        "    '📸 Photography':'Marketing',\n",
        "    'VEX':'Misc',\n",
        "    '🖼️Sticker':'Marketing',\n",
        "    'Subscription':'Subscription',\n",
        "    'Labor':'Labor',\n",
        "    'IT':'IT',\n",
        "    'Events':'Events',\n",
        "    'Operations':'Operations',\n",
        "    'Travel':'Travel',\n",
        "    'Food':'Food',\n",
        "    'Marketing':'Marketing',\n",
        "    'Teambuilding':'Teambuilding',\n",
        "    'Reimbursement':'Reimbursement',\n",
        "    'Misc':'Misc',\n",
        "    'Subscription':'Subscription',\n",
        "    'Tshirts/Hoodies':'Marketing',\n",
        "    'ComicConBakeMay2023&Tshirt':'Marketing'}"
      ],
      "metadata": {
        "id": "RsrRjRWEmHIn"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for transaction in small_data:\n",
        "#   transaction['tags'][0] = label_map[transaction['tags'][0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "Vw4O1s64lHoB",
        "outputId": "e07327ca-2015-431a-aa28-c31ef73a6bb6"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Taxes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-160-860197887619>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmall_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtransaction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'Taxes'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Train Split"
      ],
      "metadata": {
        "id": "MTv16M8GjTsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train,val = train_test_split(small_data, test_size=0.2, random_state=np.random.seed(10), shuffle=True)"
      ],
      "metadata": {
        "id": "T7ksp_e0WT97"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val,test = train_test_split(val, test_size=0.5, random_state=np.random.seed(10), shuffle=True)"
      ],
      "metadata": {
        "id": "e7api3SYXUKS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))\n",
        "print(len(val))\n",
        "print(len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpXJUfxzXqC2",
        "outputId": "6562b5f1-aa36-4da3-9fd6-6125fc7eb5ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1422\n",
            "178\n",
            "178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring Data"
      ],
      "metadata": {
        "id": "trKkwLO3jWYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get unique values\n",
        "def unique(list1):\n",
        "\n",
        "    # initialize a null list\n",
        "    unique_list = []\n",
        "\n",
        "    # traverse for all elements\n",
        "    for x in list1:\n",
        "        # check if exists in unique_list or not\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "    # print list\n",
        "    return unique_list\n",
        ""
      ],
      "metadata": {
        "id": "22SesED2jZTf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_memo = [transaction[\"memo\"] for transaction in train]"
      ],
      "metadata": {
        "id": "nQUBDnLdZQYm"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = [transaction[\"tags\"][0] for transaction in train]"
      ],
      "metadata": {
        "id": "ir0pyvx6ZRK9"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = np.array(unique(train_labels))"
      ],
      "metadata": {
        "id": "o9HVjJXFX4Jo"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initial Model: BERT"
      ],
      "metadata": {
        "id": "-fFvPp3DYIrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#specify model\n",
        "model_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "#specify tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Initializing a BERT google-bert/bert-base-uncased style configuration\n",
        "configuration = BertConfig()\n",
        "\n",
        "# Initializing a model (with random weights) from the google-bert/bert-base-uncased style configuration\n",
        "bert_model = BertModel(configuration)\n",
        "\n",
        "# Accessing the model configuration\n",
        "configuration = model.config\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCJQSEWAYH43",
        "outputId": "42e2581e-b940-46bd-dd8b-66923d2c2275"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize data\n",
        "\n",
        "train_tokenized_memos = bert_tokenizer(train_memo, max_length = 20, return_tensors = 'pt', padding = 'max_length', truncation = True)\n",
        "train_tokenized_labels = bert_tokenizer(train_labels, max_length = 4, return_tensors = 'pt', padding = 'max_length', truncation = True)['input_ids']"
      ],
      "metadata": {
        "id": "YjjU1uGH85zs"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataset\n",
        "class MemoDataset(Dataset):\n",
        "    def __init__(self, tokenized_inputs, tokenized_labels):\n",
        "        self.inputs = tokenized_inputs\n",
        "        self.labels = tokenized_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.inputs.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = MemoDataset(train_tokenized_memos, train_tokenized_labels)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "g3t4YW3fAUtL"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#move to dataloader\n",
        "batch_size = 4\n",
        "bert_train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True) # usually we shuffle, but we shuffled already above\n",
        "# bert_test_loader = DataLoader(bert_test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "N_6biflW5U5y"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "class BERTClassificationNetworkClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = bert_model\n",
        "        self.linear = torch.nn.Linear(768, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the forward pass. Apply the BERT model, then the linear layer, and\n",
        "        # then apply the sigmoid\n",
        "        bert_output = self.model(**x)\n",
        "        last_hidden_states = bert_output.last_hidden_state\n",
        "        cls_output = last_hidden_states[:,0,:]\n",
        "        linear_output = self.linear(cls_output)\n",
        "        sigmoid_output = self.sigmoid(linear_output)\n",
        "\n",
        "        return torch.squeeze(sigmoid_output) # removing 'x 1 x ' dimensions\n",
        "\n",
        "\n",
        "# loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "bert_classification_model = BERTClassificationNetworkClass().to(device)"
      ],
      "metadata": {
        "id": "CSXEiJBy1O0G"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = next(iter(bert_train_loader))\n",
        "\n",
        "test = {k:v.to(device) for k, v in test.items()}\n",
        "\n",
        "out = bert_classification_model({'input_ids': test['input_ids'], 'attention_mask': test['attention_mask']})\n",
        "\n",
        "# loss = loss_fn(out.float(), test['labels'].float())\n",
        "\n",
        "print('Output: ', out)\n",
        "# print('Loss: ', loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8rlxJWZ4R_6",
        "outputId": "5869680d-6e67-4a52-b8e3-203286fe2c12"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:  tensor([0.4799, 0.5355, 0.3709, 0.4383], device='cuda:0',\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyAfV9G_R0yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Next Steps:\n",
        "\n",
        "* Configure labels to numerical instead of text\n",
        "* Run BERT model with loss; record for initial untrained performance\n",
        "* Train\n",
        "* Incorporate additional data (amount, org_type,...) from NN layer on; potentially add more layers."
      ],
      "metadata": {
        "id": "IHZ3kPvfUAzf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wp93Obj6Uizu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}